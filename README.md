
**DAY 1:**
I have started with pandas  which is a python library for data  analysis.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6427904572823560192)


**DAY 2:**
I brushed up my knowledge on numpy  and practiced a few programs on HackerRank.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6428299354876014592)


**DAY 3:**
 I started browsing the basic difference in pandas python library.<br />

 [Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6428684475894456320)
 
 
**DAY 4, 5:**
The tasks I have accomplished are understanding :
1. cost functions
2. gradient descent
3. linear regression from scratch<br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/LinearRegression.jpg)<br />

[Linkedin post]( https://www.linkedin.com/feed/update/urn:li:activity:6429363029376360448)
 
 
 **DAY 6,7:**
By the end of #week1ofmlcode in 100 days of ml coding challenge,  I thought of taking up a course on Coursera -"Introduction to Data Science in Python" which would help me to emulate the best and I successfully completed the course which helped me in understanding data manipulation and cleaning techniques using the popular python pandas data science library.
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6430117806284599296) <br />

[code](https://lnkd.in/fR9hbRm) is available.


**DAY 8,9:**
I have learned efficient ways to use the Mathplotlib which is a plotting library for the Python programming language and its numerical mathematics extension NumPy.<br />

[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6430850443429154816)


**DAY 10,11:**
LOGISTIC REGRESSION
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6432501259634343936) <br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/LogisticRegression.jpg)<br />

[code]( https://lnkd.in/fhy7TW3) is available.


**DAY 12**:
understood the following concepts:
fixing missingdata using 'Imputer', categorical data using 'LabelEncoder' and dummy Encoding using 'OneHotEncoder' and finally splitting dataset into 'testset' and 'trainset' using train_test_split from sklearn libraries.


**DAY 13:**
gone through a few research papers which helped in understanding the real world applications of machine learning.
[ youtube](https://www.youtube.com/watch?v=SHTOI0KtZnU)


**DAY 14:**
DECISION TREE: Basic concepts and a few terminologies like prunning, information gain, gini impurity etc.
[link ](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)to reference.


**DAY 15:**
Decision tree implementation from scratch using python.
[youtube](https://www.youtube.com/watch?v=qDcl-FRnwSU&t=2440s)


**DAY 16:**
Implementation of decision tree using sklearn.
Detailed explanation on [linkedin]( https://www.linkedin.com/feed/update/urn:li:activity:6435936765810446336)<br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/DecisionTree.jpg)<br />

 [code](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/decision_tree1.ipynb)


**DAY 17:**
TOPIC: Probability
UNDERSTANDING: In machine learning, the concept of probability plays an important role. For example, we ask our machine learning algorithm how likely our result is. Thus, after knowing the importance I started a playlist of Prof. Joe Biltzstein from Harvard University.
[Source]( https://www.youtube.com/watch?v=KbB0FjPg0mw&list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)


**DAY 18:**
Watched a few videos and read some articles on ml.
[Source](https://docs.microsoft.com/en-us/azure/machine-learning/studio/data-science-for-beginners-the-5-questions-data-science-answers)<br />

[Youtube ](https://www.youtube.com/watch?v=LQEyK4POowk)

**DAY 19-23:**
Proper understanding on probability.Wrote my first blog article [INTUITIONS ON PROBABILITY](http://thrivetoknow.blogspot.com/2018/08/intuitions-on-probability.html)


**DAY 24-26:**
Participated in my first real-world [competition](https://www.machinehack.com/course/predicting-house-prices-in-bengaluru/?renew)

**DAY 27,28:**
Naive Bayes Classifier:
This algorithm is mostly used in text classification/ Spam Filtering/ Sentiment Analysis/Recommendation System and with problems having multiple classes.Knew 3 different popular [Naive Bayes classifiers](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
).


**DAY 29:**
Naive Bayes
[Infografic](https://www.linkedin.com/feed/update/urn:li:activity:6441790742829588480) <br />

![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/NaiveBayes1.jpg)


**DAY 30:**
[Naive bayes](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/Naive-bayes) code from scratch using python
![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/NaiveBayes2.jpg)


**DAY 30-34:**
[SVM](https://eduvatecom.wordpress.com/2018/09/16/large-margin-classifier-svm/) article.


**DAY 35-37:**
Linear and non Linear classification using SVM:<br/>
Based on the dataset, if it is linearly separable  LinearSVM can be used or
else  kernel trick is used to project the data into a high-dimensional space before attempting to find a hyperplane.
<br/>
Spam classification:<br/>
Many email services today provide spam filters that are able to classify emails 
into spam and non-spam email with high accuracy.SVMs are used to build own spam filter.<br/>
![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/svm_infographic.png)

[Github code](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/SupportVectorMachine)


**DAY 38-40:**</br>
Ensemble learning helps improve machine learning results by combining several models. This approach allows the production of better predictive performance compared to a single model.</br>
references:https://blog.statsbot.co/ensemble-learning-d1dcd548e936
[Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:6448941159027965952/)
<br/>![](https://github.com/neha-duggirala/100DaysOfMLCode/blob/master/infographics/Ensemble_Learning.png)



**DAY 41:**</br>
Participated in an [online hackathon](https://www.techgig.com/hackathon/question/OGJobFRZZWJSVWlITTk1cnpXQWIraG1VaE5CMjdWWXpTU3JDYkpNRVI3RT0=/1)
on data science 


**DAY 42:**</br>
By using Sklearn libraries [implemented](https://github.com/neha-duggirala/100DaysOfMLCode/tree/master/Ensemble%20Learning)
</br>Useful [resources]()
